{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import operator\n",
    "import time\n",
    "dataset = 'diginetica'\n",
    "ds = 'data/diginetica/train-item-views2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sessionId    310324\n",
       "itemId       122993\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv(ds, sep=';')\n",
    "df['sessionId'] = df['sessionId'].astype('category').cat.codes\n",
    "df['itemId'] = df['itemId'].astype('category').cat.codes\n",
    "df[['sessionId', 'itemId']].nunique()\n",
    "# df.to_csv('./datasets/diginetica/train-item-views.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of session clicks: 310324\n"
     ]
    }
   ],
   "source": [
    "with open(ds, \"r\") as f:\n",
    "    if dataset == 'retailrocket' or dataset == 'diginetica':\n",
    "        lines = f.readlines()[1:]  # skip the first line\n",
    "    else:\n",
    "        lines = f.readlines()\n",
    "    sess_clicks = {}\n",
    "    sess_date = {}\n",
    "    for line in lines:\n",
    "        if dataset == 'retailrocket':\n",
    "            data = [int(x) for x in line.split()]\n",
    "            sess_id = data[3]\n",
    "            item = data[2]\n",
    "            timestamp = data[0]\n",
    "        elif dataset == 'yoochoose':\n",
    "            data = [x for x in line.split(\",\")]\n",
    "            sess_id = int(data[0])\n",
    "            item = int(data[2])\n",
    "            timestamp = time.mktime(time.strptime(data[1][:19], '%Y-%m-%dT%H:%M:%S'))\n",
    "        elif dataset == 'diginetica':\n",
    "            data = [x for x in line.split(\";\")]\n",
    "            sess_id = int(data[0])\n",
    "            timestamp = time.mktime(time.strptime(data[4][:-1], '%Y-%m-%d'))\n",
    "            timeframe = int(data[3])\n",
    "            item = (int(data[2]), timestamp, timeframe)\n",
    "\n",
    "        if sess_id in sess_clicks:\n",
    "            sess_clicks[sess_id] += [item]\n",
    "            sess_date[sess_id] = timestamp  # timestamp取最后一个item的timestamp\n",
    "        else:\n",
    "            sess_clicks[sess_id] = [item]\n",
    "            sess_date[sess_id] = timestamp  # timestamp取最后一个item的timestamp\n",
    "\n",
    "    if dataset == 'diginetica':\n",
    "        for i in list(sess_clicks):\n",
    "            sorted_clicks = sorted(sess_clicks[i], key=operator.itemgetter(1))\n",
    "            # sorted_clicks = sorted(sess_clicks[i], key=lambda x: (x[1], x[2]))  # 以日期为第一关键字,timeframe为第二关键字\n",
    "            sess_clicks[i] = [c[0] for c in sorted_clicks]\n",
    "print(\"length of session clicks: %d\" % len(sess_clicks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after filter out length of 3, length of session clicks: 121863\n",
      "after item<5 , length of session clicks: 104676\n",
      "split timestamp: 1464114600\n"
     ]
    }
   ],
   "source": [
    "filter_len = 3\n",
    "for s in list(sess_clicks):\n",
    "    if len(sess_clicks[s]) <= filter_len:\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "print(\"after filter out length of %d, length of session clicks: %d\" % (filter_len, len(sess_clicks)))\n",
    "\n",
    "# Count number of times each item appears\n",
    "item_counts = {}\n",
    "for s in sess_clicks:\n",
    "    seq = sess_clicks[s]\n",
    "    for iid in seq:\n",
    "        if iid in item_counts:\n",
    "            item_counts[iid] += 1\n",
    "        else:\n",
    "            item_counts[iid] = 1\n",
    "\n",
    "sorted_counts = sorted(item_counts.items(), key=operator.itemgetter(1))\n",
    "\n",
    "for s in list(sess_clicks):\n",
    "    curseq = sess_clicks[s]\n",
    "    filseq = list(filter(lambda i: item_counts[i] >= 5, curseq))\n",
    "    if len(filseq) <= filter_len:\n",
    "        del sess_clicks[s]\n",
    "        del sess_date[s]\n",
    "    else:\n",
    "        sess_clicks[s] = filseq\n",
    "print(\"after item<5 , length of session clicks: %d\" % len(sess_clicks))\n",
    "\n",
    "# split out train set and test set based on date\n",
    "dates = list(sess_date.items())\n",
    "max_timestamp = dates[0][1]\n",
    "\n",
    "for _, date in dates:\n",
    "    max_timestamp = max(max_timestamp, date)  # latest date\n",
    "\n",
    "if dataset == 'retailrocket' or dataset == 'diginetica':\n",
    "    split_timestamp = max_timestamp - 7 * 86400\n",
    "else:\n",
    "    split_timestamp = max_timestamp - 86400\n",
    "\n",
    "print(\"split timestamp: %d\" % split_timestamp)\n",
    "train_session = filter(lambda x: x[1] < split_timestamp, dates)\n",
    "test_session = filter(lambda x: x[1] > split_timestamp, dates)\n",
    "\n",
    "# Sort sessions by date\n",
    "train_session = sorted(train_session, key=operator.itemgetter(1))\n",
    "test_session = sorted(test_session, key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_num: 38053\n",
      "training: 95425\n",
      "testing: 8143\n",
      "after split,training: 95425\n",
      "after split,testing: 8143\n"
     ]
    }
   ],
   "source": [
    "item_dict = {}\n",
    "# convert training sessions to sequences and renumber the items\n",
    "def get_train():\n",
    "    tra_sid = []\n",
    "    tra_seq = []\n",
    "    tra_timestamp = []\n",
    "    item_cnt = 1\n",
    "    for s, t in train_session:\n",
    "        seq = sess_clicks[s]\n",
    "        outseq = []\n",
    "        if len(seq) < filter_len:  # Doesn't occur\n",
    "            continue\n",
    "        for i in seq:\n",
    "            if i in item_dict:\n",
    "                outseq += [item_dict[i]]\n",
    "            else:\n",
    "                item_dict[i] = item_cnt\n",
    "                outseq += [item_dict[i]]\n",
    "                item_cnt += 1\n",
    "        tra_sid += [s]\n",
    "        tra_timestamp += [t]\n",
    "        tra_seq += [outseq]\n",
    "    print('item_num: %d' % (item_cnt - 1))\n",
    "    return tra_sid, tra_timestamp, tra_seq\n",
    "\n",
    "\n",
    "# Convert test sessions to sequences, ignoring items that do not appear in training set\n",
    "def get_test():\n",
    "    tes_sid = []\n",
    "    tes_seq = []\n",
    "    tes_timestamp = []\n",
    "    for s, t in test_session:\n",
    "        seq = sess_clicks[s]\n",
    "        outseq = []\n",
    "        for i in seq:\n",
    "            if i in item_dict:\n",
    "                outseq += [item_dict[i]]\n",
    "        if len(outseq) < filter_len:\n",
    "            continue\n",
    "        tes_sid += [s]\n",
    "        tes_timestamp += [t]\n",
    "        tes_seq += [outseq]\n",
    "    return tes_sid, tes_timestamp, tes_seq\n",
    "\n",
    "\n",
    "train_sid, train_timestamp, train_seq = get_train()\n",
    "test_sid, test_timestamp, test_seq = get_test()\n",
    "print(\"training: %d\" % len(train_sid))\n",
    "print(\"testing: %d\" % len(test_sid))\n",
    "\n",
    "\n",
    "# train_data = (train_sid, train_seq, train_timestamp)\n",
    "# pickle.dump(train_data, open('./datasets/retailrocket/train_seq_2.txt', 'wb'))\n",
    "\n",
    "\n",
    "# split sequence\n",
    "def split_seq(sid, timestamp, seq):\n",
    "    x = []\n",
    "    t = []\n",
    "    y = []\n",
    "    s_id = []\n",
    "    for sid, seq, timestamp in zip(sid, seq, timestamp):\n",
    "        if filter_len == 2:\n",
    "            temp = len(seq) - 1\n",
    "        else:\n",
    "            temp = len(seq)\n",
    "        # for i in range(1, temp):\n",
    "            i=1\n",
    "            y += [seq[-i]]\n",
    "            x += [seq[:-i]]\n",
    "            t += [timestamp]\n",
    "            s_id += [sid]\n",
    "    return x, t, y, s_id\n",
    "\n",
    "\n",
    "def split_seq_train(sid, timestamp, seq):\n",
    "    x = []\n",
    "    t = []\n",
    "    s_id = []\n",
    "    for sid, seq, timestamp in zip(sid, seq, timestamp):\n",
    "        if len(seq) > filter_len:\n",
    "            x += [seq]\n",
    "            t += [timestamp]\n",
    "            s_id += [sid]\n",
    "        if filter_len == 2:\n",
    "            temp = len(seq) - 1\n",
    "        else:\n",
    "            temp = len(seq)\n",
    "        for i in range(1, temp):\n",
    "            x += [seq[:-i]]\n",
    "            t += [timestamp]\n",
    "            s_id += [sid]\n",
    "    return x, t, s_id\n",
    "\n",
    "\n",
    "tr_seq, tr_timestamp, tr_predict, tr_sid = split_seq(train_sid, train_timestamp, train_seq)\n",
    "te_seq, te_timestamp, te_predict, te_sid = split_seq(test_sid, test_timestamp, test_seq)\n",
    "\n",
    "print(\"after split,training: %d\" % len(tr_seq))\n",
    "print(\"after split,testing: %d\" % len(te_seq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renumber_lists(list_of_lists):\n",
    "    flat_list = [item for sublist in list_of_lists for item in sublist]\n",
    "    unique_numbers = sorted(set(flat_list))\n",
    "    pd.Series(flat_list).astype('category').cat.codes.to_list()\n",
    "    number_mapping = {num: i for i, num in enumerate(unique_numbers)}\n",
    "    new_list_of_lists = [[number_mapping[item] for item in sublist] for sublist in list_of_lists]\n",
    "    return new_list_of_lists\n",
    "\n",
    "tr_seq = renumber_lists(tr_seq)\n",
    "tr_sid = pd.Series(tr_sid).astype('category').cat.codes.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = (tr_sid, tr_seq, tr_timestamp, tr_predict)\n",
    "pickle.dump(train_data, open('data/diginetica/train_session.txt', 'wb'))\n",
    "print(\"finish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
